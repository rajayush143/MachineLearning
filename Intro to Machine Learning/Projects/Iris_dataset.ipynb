{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Iris.ipynb","provenance":[{"file_id":"1ZkWsTLb-Ty0j4ZuoSlbQhY5Rpc__FGyv","timestamp":1582483895989},{"file_id":"1qOJIDjyrNHh7-QhIOz9b93BgntJPbMLZ","timestamp":1543188629620},{"file_id":"1OF4YLTwLUQo6h6F20-SJOhDP9IAV56Nr","timestamp":1543187063266}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eM9iAeQotrUw","colab_type":"text"},"source":["# ML Bootcamp: Logistic Regression\n","\n","In this lab, we will provide an interactive demonstration of logistic regression, predicting what number is represented by handwritten images of digits 0-9. \n","\n","Let's first start by loading the data in. We will use the scikit-learn digits dataset as a reference. Each piece of data consists of a representation of a handwritten digit and a label corresponding to the number of the drawn digit."]},{"cell_type":"code","metadata":{"id":"KrBN3rwBt4bD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592374551767,"user_tz":420,"elapsed":506,"user":{"displayName":"Ayush Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiidtS5N__ylVZXEyh0ay7E6S9FjEJHLu9yNSQxsA=s64","userId":"02422483954573724390"}},"outputId":"deb1a6a8-da5f-47b3-e550-22f2e1610b2c"},"source":["# checking setosa vs. not setosa\n","import numpy as np\n","from sklearn import datasets\n","\n","\n","iris = datasets.load_iris()\n","iris_X = iris.data\n","iris_y = iris.target\n","\n","print(iris_X)\n","print(iris_y)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[[5.1 3.5 1.4 0.2]\n"," [4.9 3.  1.4 0.2]\n"," [4.7 3.2 1.3 0.2]\n"," [4.6 3.1 1.5 0.2]\n"," [5.  3.6 1.4 0.2]\n"," [5.4 3.9 1.7 0.4]\n"," [4.6 3.4 1.4 0.3]\n"," [5.  3.4 1.5 0.2]\n"," [4.4 2.9 1.4 0.2]\n"," [4.9 3.1 1.5 0.1]\n"," [5.4 3.7 1.5 0.2]\n"," [4.8 3.4 1.6 0.2]\n"," [4.8 3.  1.4 0.1]\n"," [4.3 3.  1.1 0.1]\n"," [5.8 4.  1.2 0.2]\n"," [5.7 4.4 1.5 0.4]\n"," [5.4 3.9 1.3 0.4]\n"," [5.1 3.5 1.4 0.3]\n"," [5.7 3.8 1.7 0.3]\n"," [5.1 3.8 1.5 0.3]\n"," [5.4 3.4 1.7 0.2]\n"," [5.1 3.7 1.5 0.4]\n"," [4.6 3.6 1.  0.2]\n"," [5.1 3.3 1.7 0.5]\n"," [4.8 3.4 1.9 0.2]\n"," [5.  3.  1.6 0.2]\n"," [5.  3.4 1.6 0.4]\n"," [5.2 3.5 1.5 0.2]\n"," [5.2 3.4 1.4 0.2]\n"," [4.7 3.2 1.6 0.2]\n"," [4.8 3.1 1.6 0.2]\n"," [5.4 3.4 1.5 0.4]\n"," [5.2 4.1 1.5 0.1]\n"," [5.5 4.2 1.4 0.2]\n"," [4.9 3.1 1.5 0.2]\n"," [5.  3.2 1.2 0.2]\n"," [5.5 3.5 1.3 0.2]\n"," [4.9 3.6 1.4 0.1]\n"," [4.4 3.  1.3 0.2]\n"," [5.1 3.4 1.5 0.2]\n"," [5.  3.5 1.3 0.3]\n"," [4.5 2.3 1.3 0.3]\n"," [4.4 3.2 1.3 0.2]\n"," [5.  3.5 1.6 0.6]\n"," [5.1 3.8 1.9 0.4]\n"," [4.8 3.  1.4 0.3]\n"," [5.1 3.8 1.6 0.2]\n"," [4.6 3.2 1.4 0.2]\n"," [5.3 3.7 1.5 0.2]\n"," [5.  3.3 1.4 0.2]\n"," [7.  3.2 4.7 1.4]\n"," [6.4 3.2 4.5 1.5]\n"," [6.9 3.1 4.9 1.5]\n"," [5.5 2.3 4.  1.3]\n"," [6.5 2.8 4.6 1.5]\n"," [5.7 2.8 4.5 1.3]\n"," [6.3 3.3 4.7 1.6]\n"," [4.9 2.4 3.3 1. ]\n"," [6.6 2.9 4.6 1.3]\n"," [5.2 2.7 3.9 1.4]\n"," [5.  2.  3.5 1. ]\n"," [5.9 3.  4.2 1.5]\n"," [6.  2.2 4.  1. ]\n"," [6.1 2.9 4.7 1.4]\n"," [5.6 2.9 3.6 1.3]\n"," [6.7 3.1 4.4 1.4]\n"," [5.6 3.  4.5 1.5]\n"," [5.8 2.7 4.1 1. ]\n"," [6.2 2.2 4.5 1.5]\n"," [5.6 2.5 3.9 1.1]\n"," [5.9 3.2 4.8 1.8]\n"," [6.1 2.8 4.  1.3]\n"," [6.3 2.5 4.9 1.5]\n"," [6.1 2.8 4.7 1.2]\n"," [6.4 2.9 4.3 1.3]\n"," [6.6 3.  4.4 1.4]\n"," [6.8 2.8 4.8 1.4]\n"," [6.7 3.  5.  1.7]\n"," [6.  2.9 4.5 1.5]\n"," [5.7 2.6 3.5 1. ]\n"," [5.5 2.4 3.8 1.1]\n"," [5.5 2.4 3.7 1. ]\n"," [5.8 2.7 3.9 1.2]\n"," [6.  2.7 5.1 1.6]\n"," [5.4 3.  4.5 1.5]\n"," [6.  3.4 4.5 1.6]\n"," [6.7 3.1 4.7 1.5]\n"," [6.3 2.3 4.4 1.3]\n"," [5.6 3.  4.1 1.3]\n"," [5.5 2.5 4.  1.3]\n"," [5.5 2.6 4.4 1.2]\n"," [6.1 3.  4.6 1.4]\n"," [5.8 2.6 4.  1.2]\n"," [5.  2.3 3.3 1. ]\n"," [5.6 2.7 4.2 1.3]\n"," [5.7 3.  4.2 1.2]\n"," [5.7 2.9 4.2 1.3]\n"," [6.2 2.9 4.3 1.3]\n"," [5.1 2.5 3.  1.1]\n"," [5.7 2.8 4.1 1.3]\n"," [6.3 3.3 6.  2.5]\n"," [5.8 2.7 5.1 1.9]\n"," [7.1 3.  5.9 2.1]\n"," [6.3 2.9 5.6 1.8]\n"," [6.5 3.  5.8 2.2]\n"," [7.6 3.  6.6 2.1]\n"," [4.9 2.5 4.5 1.7]\n"," [7.3 2.9 6.3 1.8]\n"," [6.7 2.5 5.8 1.8]\n"," [7.2 3.6 6.1 2.5]\n"," [6.5 3.2 5.1 2. ]\n"," [6.4 2.7 5.3 1.9]\n"," [6.8 3.  5.5 2.1]\n"," [5.7 2.5 5.  2. ]\n"," [5.8 2.8 5.1 2.4]\n"," [6.4 3.2 5.3 2.3]\n"," [6.5 3.  5.5 1.8]\n"," [7.7 3.8 6.7 2.2]\n"," [7.7 2.6 6.9 2.3]\n"," [6.  2.2 5.  1.5]\n"," [6.9 3.2 5.7 2.3]\n"," [5.6 2.8 4.9 2. ]\n"," [7.7 2.8 6.7 2. ]\n"," [6.3 2.7 4.9 1.8]\n"," [6.7 3.3 5.7 2.1]\n"," [7.2 3.2 6.  1.8]\n"," [6.2 2.8 4.8 1.8]\n"," [6.1 3.  4.9 1.8]\n"," [6.4 2.8 5.6 2.1]\n"," [7.2 3.  5.8 1.6]\n"," [7.4 2.8 6.1 1.9]\n"," [7.9 3.8 6.4 2. ]\n"," [6.4 2.8 5.6 2.2]\n"," [6.3 2.8 5.1 1.5]\n"," [6.1 2.6 5.6 1.4]\n"," [7.7 3.  6.1 2.3]\n"," [6.3 3.4 5.6 2.4]\n"," [6.4 3.1 5.5 1.8]\n"," [6.  3.  4.8 1.8]\n"," [6.9 3.1 5.4 2.1]\n"," [6.7 3.1 5.6 2.4]\n"," [6.9 3.1 5.1 2.3]\n"," [5.8 2.7 5.1 1.9]\n"," [6.8 3.2 5.9 2.3]\n"," [6.7 3.3 5.7 2.5]\n"," [6.7 3.  5.2 2.3]\n"," [6.3 2.5 5.  1.9]\n"," [6.5 3.  5.2 2. ]\n"," [6.2 3.4 5.4 2.3]\n"," [5.9 3.  5.1 1.8]]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AOEiWubk1eT-","colab_type":"text"},"source":["We can visualize some of the examples in our dataset."]},{"cell_type":"code","metadata":{"id":"cEhyUqfq8fjm","colab_type":"code","colab":{}},"source":["# changed setosa into 1 and non-setosas into -1\n","\n","for i in range(len(iris_y)):\n","  if iris_y[i] == 0:\n","    iris_y[i] = 1\n","  else:\n","    iris_y[i] = -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JS4unwRTuDWZ","colab_type":"text"},"source":["As we usually do in machine learning, let's separate our data into a subset to **train** on and a subset to **test** on. "]},{"cell_type":"code","metadata":{"id":"_nmh25-GujW6","colab_type":"code","colab":{}},"source":["np.random.seed(0)\n","indices = np.random.permutation(len(iris_X))\n","\n","# |with_ex| is the number of test examples\n","# Precondition: with_ex < 0\n","with_ex = -50\n","\n","iris_X_train = iris_X[indices[:with_ex]] # assigning train x \n","iris_y_train = iris_y[indices[:with_ex]] # assigning train y\n","\n","iris_X_test = iris_X[indices[with_ex:]] # assigning test x\n","iris_y_test = iris_y[indices[with_ex:]] # assigning test y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aMIjPDDcuzG0","colab_type":"text"},"source":["Now, we will use scikit-learn's implementation of logistic regression. We will train our model on the training subset, and then use that model to make predictions for our test set."]},{"cell_type":"code","metadata":{"id":"-NOVp4_ow7s5","colab_type":"code","colab":{}},"source":["#LOGISTIC REGRESSION\n","#from sklearn import linear_model\n","\n","#model = linear_model.LogisticRegression()\n","\n","#SVM\n","from sklearn import svm\n","\n","model = svm.SVC(kernel='linear')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WjyEmYyn89tw","colab_type":"text"},"source":["Now, we can train the classifier on the training subset."]},{"cell_type":"code","metadata":{"id":"iLFsV6diyUF2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1582497295027,"user_tz":480,"elapsed":610,"user":{"displayName":"Ayush Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mATBDSRsmcLq6SQ5dFGOWcOyaOVf_JpxGMpk_RhoQ=s64","userId":"02422483954573724390"}},"outputId":"aed38e77-8b54-4f73-d5bc-d4ef412c95ba"},"source":["model.fit(iris_X_train, iris_y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"markdown","metadata":{"id":"yBmmKDJvzSTy","colab_type":"text"},"source":["With the trained models, we can make predictions on the testing subset. "]},{"cell_type":"code","metadata":{"id":"CZFoq84YzXMb","colab_type":"code","colab":{}},"source":["preds = model.predict(iris_X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p3Jdb9h3zmat","colab_type":"text"},"source":["Let's now visualize our predictions!"]},{"cell_type":"markdown","metadata":{"id":"NQLKnWrWBTZZ","colab_type":"text"},"source":["Finally, we can compute our classification accuracy, or the percentage of examples in the test subset classified correctly. The following code snippet computes the accuracy."]},{"cell_type":"code","metadata":{"id":"qqwgZxwpBjuY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1582497295035,"user_tz":480,"elapsed":548,"user":{"displayName":"Ayush Raj","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mATBDSRsmcLq6SQ5dFGOWcOyaOVf_JpxGMpk_RhoQ=s64","userId":"02422483954573724390"}},"outputId":"824f9fad-527d-4f05-ccc7-510ab6665c92"},"source":["# Compute number of examples classified correctly\n","\n","num_correct = 0\n","for i in range(len(preds)):\n","  if preds[i] == iris_y_test[i]:\n","    num_correct += 1\n","    \n","print(\"The fraction of correctly classified examples in the test set is: \" + str(num_correct / len(preds)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The fraction of correctly classified examples in the test set is: 1.0\n"],"name":"stdout"}]}]}